{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 1 - Group 7*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpra \n",
    "This assignment uses texts from 3 different genres: \n",
    "\n",
    "-Text from a novel\n",
    "-Text from a stageplay \n",
    "-Text from a TV show \n",
    "\n",
    "Sources:\n",
    "\n",
    "[Sherlock Holmes](https://sherlock-holm.es/stories/plain-text/cano.txt)\n",
    "\n",
    "[Macbeth](https://dracor.org/shake/macbeth#downloads)\n",
    "\n",
    "[Breaking Bad](https://transcripts.foreverdreaming.org/viewforum.php?f=165)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect of corpus in Corpora into a list\n",
    "corpusList = os.listdir(os.getcwd() + \"/Corpora/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCleanSplit(corpus):\n",
    "    with open(\"./Corpora/\" + corpus, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        cleanedText = re.sub(\" *[^\\w\\s]+\", \" \", text)\n",
    "        splitedText = cleanedText.split()\n",
    "    return splitedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of BreakingBadSeason1.txt is 24875\n",
      "The length of macbethspoken.txt is 16708\n",
      "The length of SherlockHolmes.txt is 668228\n"
     ]
    }
   ],
   "source": [
    "# remove all punctuations and get length\n",
    "def getLength(corpus):\n",
    "    length = len(readCleanSplit(corpus))\n",
    "    return length\n",
    "\n",
    "# print result\n",
    "for corpus in corpusList:\n",
    "    print(\"The length of {} is {}\".format(corpus, getLength(corpus)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lexical diversity of BreakingBadSeason1.txt is 0.11798995\n",
      "The lexical diversity of macbethspoken.txt is 0.18996888\n",
      "The lexical diversity of SherlockHolmes.txt is 0.02871924\n"
     ]
    }
   ],
   "source": [
    "# define lexical diversity function\n",
    "def lexDiv(corpus):\n",
    "    wordList = readCleanSplit(corpus)\n",
    "    tokens = len(wordList)\n",
    "    types = len(set(w.lower() for w in wordList))\n",
    "    return types / tokens\n",
    "\n",
    "# print result\n",
    "for corpus in corpusList:\n",
    "    print(\"The lexical diversity of {} is {:.8f}\".format(corpus,lexDiv(corpus)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BreakingBadSeason1.txt:\n",
      "The 10 most common words starting with 'a': \n",
      "[('a', 432), ('and', 290), ('all', 151), ('about', 124), ('are', 118), ('at', 100), ('as', 50), ('an', 41), ('any', 30), ('am', 29)]\n",
      "The 10 most common words starting with 'e': \n",
      "[('even', 32), ('enough', 19), ('ever', 18), ('every', 18), ('emilio', 15), ('elliott', 15), ('else', 11), ('excuse', 11), ('easy', 10), ('everybody', 9)]\n",
      "The 10 most common words starting with 'i': \n",
      "[('i', 935), ('it', 570), ('is', 264), ('in', 220), ('if', 62), ('into', 15), ('isn', 13), ('idea', 12), ('iron', 5), ('interest', 5)]\n",
      "The 10 most common words starting with 'o': \n",
      "[('of', 236), ('on', 151), ('out', 110), ('okay', 104), ('one', 81), ('oh', 75), ('or', 51), ('our', 48), ('off', 37), ('over', 26)]\n",
      "The 10 most common words starting with 'u': \n",
      "[('up', 119), ('us', 50), ('used', 18), ('uh', 16), ('understand', 15), ('until', 11), ('use', 7), ('um', 6), ('uncle', 4), ('understanding', 4)]\n",
      "\n",
      "macbethspoken.txt:\n",
      "The 10 most common words starting with 'a': \n",
      "[('and', 513), ('a', 215), ('all', 91), ('as', 88), ('are', 74), ('at', 52), ('am', 30), ('an', 27), ('again', 21), ('art', 19)]\n",
      "The 10 most common words starting with 'e': \n",
      "[('each', 13), ('every', 13), ('ere', 12), ('even', 12), ('eyes', 11), ('else', 11), ('eye', 11), ('er', 10), ('enough', 10), ('ever', 8)]\n",
      "The 10 most common words starting with 'i': \n",
      "[('i', 363), ('in', 195), ('is', 187), ('it', 151), ('if', 45), ('into', 11), ('itself', 9), ('issue', 6), ('indeed', 5), ('innocent', 5)]\n",
      "The 10 most common words starting with 'o': \n",
      "[('of', 325), ('our', 119), ('on', 62), ('o', 48), ('or', 36), ('one', 30), ('out', 26), ('own', 17), ('other', 15), ('only', 12)]\n",
      "The 10 most common words starting with 'u': \n",
      "[('upon', 63), ('us', 55), ('up', 26), ('under', 8), ('use', 6), ('unto', 3), ('undone', 3), ('unnatural', 3), ('unfix', 2), ('used', 2)]\n",
      "\n",
      "SherlockHolmes.txt:\n",
      "The 10 most common words starting with 'a': \n",
      "[('and', 17578), ('a', 15828), ('as', 4755), ('at', 4625), ('all', 2418), ('an', 2297), ('are', 2129), ('about', 1075), ('am', 1009), ('any', 938)]\n",
      "The 10 most common words starting with 'e': \n",
      "[('eyes', 642), ('every', 489), ('ever', 433), ('enough', 399), ('end', 397), ('even', 369), ('evening', 306), ('each', 259), ('else', 195), ('entered', 186)]\n",
      "The 10 most common words starting with 'i': \n",
      "[('i', 17322), ('it', 11095), ('in', 10750), ('is', 6648), ('if', 2065), ('into', 1462), ('its', 458), ('instant', 293), ('indeed', 265), ('inspector', 262)]\n",
      "The 10 most common words starting with 'o': \n",
      "[('of', 16694), ('on', 2756), ('one', 2589), ('out', 1863), ('our', 1708), ('or', 1350), ('only', 1086), ('over', 1078), ('other', 881), ('own', 736)]\n",
      "The 10 most common words starting with 'u': \n",
      "[('upon', 2586), ('up', 1662), ('us', 1528), ('until', 460), ('under', 331), ('understand', 252), ('use', 180), ('used', 164), ('usual', 78), ('unless', 75)]\n"
     ]
    }
   ],
   "source": [
    "# top 10 words with given initial\n",
    "def initial_top10(corpus, initial):\n",
    "    wordList = readCleanSplit(corpus)\n",
    "    # only put words with initial X in list\n",
    "    processedList = []\n",
    "    for w in wordList:\n",
    "        if w[0] == initial.upper() or w[0] == initial.lower():\n",
    "            processedList.append(w.lower())\n",
    "            \n",
    "    fDist = nltk.FreqDist(nltk.Text(processedList))\n",
    "    return fDist.most_common(10)\n",
    "    \n",
    "for corpus in corpusList:\n",
    "    print(\"\\n{}:\".format(corpus))\n",
    "    for vowel in \"aeiou\":\n",
    "        print(\"The 10 most common words starting with '{}': \\n{}\".format(vowel, initial_top10(corpus,vowel)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sentence in Breaking Bad: The right-handed isomer of the drug, Thalidomide is a perfectly fine good medicine to give to a pregnant woman to prevent morning sickness but, make the mistake of giving that same pregnant woman the left-handed isomer of the drug Thalidomide, and her child will be born with horrible birth defects (50 words)\n",
      "Longest sentence in Macbeth: What’s more to do ,\n",
      "Which would be planted newly with the time ,\n",
      "As calling home our exiled friends abroad\n",
      "That fled the snares of watchful tyranny ,\n",
      "Producing forth the cruel ministers\n",
      "Of this dead butcher and his fiend-like queen\n",
      "( Who , as ’tis thought , by self and violent hands ,\n",
      "Took off her life ) — this , and what needful else\n",
      "That calls upon us , by the grace of grace ,\n",
      "We will perform in measure , time , and place (88 words)\n",
      "Longest sentence in Sherlock Holmes: \"\n",
      "\n",
      "     \"When you combine the ideas of whistles at night, the presence of a\n",
      "     band of gipsies who are on intimate terms with this old doctor, the\n",
      "     fact that we have every reason to believe that the doctor has an\n",
      "     interest in preventing his stepdaughter's marriage, the dying\n",
      "     allusion to a band, and, finally, the fact that Miss Helen Stoner\n",
      "     heard a metallic clang, which might have been caused by one of those\n",
      "     metal bars that secured the shutters falling back into its place, I\n",
      "     think that there is good ground to think that the mystery may be\n",
      "     cleared along those lines (102 words)\n"
     ]
    }
   ],
   "source": [
    "# set the path to the corpus directory\n",
    "corpus_path = \"Corpora\"\n",
    "\n",
    "# got a list of all files in the corpus directory\n",
    "corpus_files = [os.path.join(corpus_path, f) for f in os.listdir(corpus_path)]\n",
    "\n",
    "# created a list of labels for the files\n",
    "file_labels = [\"Breaking Bad\", \"Macbeth\", \"Sherlock Holmes\"]\n",
    "\n",
    "# Created a loop\n",
    "for i, corpus_file in enumerate(corpus_files):\n",
    " # open the file\n",
    "    with open(corpus_file, 'r', encoding='utf-8') as f:\n",
    " # read in the entire corpus\n",
    "        corpus = f.read()\n",
    "    \n",
    " # Used regular expressions to split the corpus into sentences\n",
    "        sentences = re.split('[.?!]', corpus)\n",
    "    \n",
    "# Found the longest sentence and removed any whitespace\n",
    "        longest_sentence = max(sentences, key=len).strip()\n",
    "    \n",
    " # count the number of words in the longest sentence\n",
    "        num_words = len(longest_sentence.split())\n",
    "    \n",
    "# printed the longest sentence and number of words, starting with an informative label\n",
    "        print(f\"Longest sentence in {file_labels[i]}: {longest_sentence} ({num_words} words)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed version of the longest sentence in Breaking Bad: \" \"when you combin the idea of whistl at night, the presenc of a band of gipsi who are on intim term with this old doctor, the fact that we have everi reason to believ that the doctor has an interest in prevent his stepdaught marriage, the die allus to a band, and, finally, the fact that miss helen stoner heard a metal clang, which might have been caus by one of those metal bar that secur the shutter fall back into it place, i think that there is good ground to think that the mysteri may be clear along those line\n",
      "Stemmed version of the longest sentence in Macbeth: \" \"when you combin the idea of whistl at night, the presenc of a band of gipsi who are on intim term with this old doctor, the fact that we have everi reason to believ that the doctor has an interest in prevent his stepdaught marriage, the die allus to a band, and, finally, the fact that miss helen stoner heard a metal clang, which might have been caus by one of those metal bar that secur the shutter fall back into it place, i think that there is good ground to think that the mysteri may be clear along those line\n",
      "Stemmed version of the longest sentence in Sherlock Holmes: \" \"when you combin the idea of whistl at night, the presenc of a band of gipsi who are on intim term with this old doctor, the fact that we have everi reason to believ that the doctor has an interest in prevent his stepdaught marriage, the die allus to a band, and, finally, the fact that miss helen stoner heard a metal clang, which might have been caus by one of those metal bar that secur the shutter fall back into it place, i think that there is good ground to think that the mysteri may be clear along those line\n"
     ]
    }
   ],
   "source": [
    "# Created a Snowball Stemmer (NLTK) object\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Looped through the corpus files\n",
    "for i, corpus_file in enumerate(corpus_files):\n",
    "\n",
    "# Used the Snowball Stemmer to create a list of stemmed words from the longest sentence\n",
    "        stemmed_longest_sentence = [stemmer.stem(word) for word in longest_sentence.split()]\n",
    "    \n",
    "# Print the stemmed version of the longest sentence for this file\n",
    "        print(f\"Stemmed version of the longest sentence in {file_labels[i]}: {' '.join(stemmed_longest_sentence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 1393, '.': 1152, '’': 514, 'the': 502, 'and': 352, 'I': 348, 'of': 303, 'to': 297, '?': 239, 'a': 190, ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpus_root = \"Corpora\"\n",
    "mycorpus = PlaintextCorpusReader(corpus_root, '.*', encoding = \"utf8\")\n",
    "macbeth = nltk.Text(mycorpus.words('macbethspoken.txt'))\n",
    "nltk.FreqDist(macbeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the concordances for the top three most frequent words in 'Macbeth':\n",
      "Displaying 25 of 633 matches:\n",
      "under , lightning , or in rain ? When the hurly - burly ’ s done , When the bat\n",
      "hen the hurly - burly ’ s done , When the battle ’ s lost and won . That will b\n",
      "e ’ s lost and won . That will be ere the set of sun . Where the place ? Upon t\n",
      "at will be ere the set of sun . Where the place ? Upon the heath . There to mee\n",
      "e set of sun . Where the place ? Upon the heath . There to meet with Macbeth . \n",
      "ul , and foul is fair ; Hover through the fog and filthy air . What bloody man \n",
      "eport , As seemeth by his plight , of the revolt The newest state . This is the\n",
      "seemeth by his plight , of the revolt The newest state . This is the sergeant W\n",
      "the revolt The newest state . This is the sergeant Who , like a good and hardy \n",
      "vity . — Hail , brave friend ! Say to the King the knowledge of the broil As th\n",
      "Hail , brave friend ! Say to the King the knowledge of the broil As thou didst \n",
      "nd ! Say to the King the knowledge of the broil As thou didst leave it . Doubtf\n",
      " cling together And choke their art . The merciless Macdonwald ( Worthy to be a\n",
      " ( Worthy to be a rebel , for to that The multiplying villainies of nature Do s\n",
      "es of nature Do swarm upon him ) from the Western Isles Of kerns and gallowglas\n",
      " carved out his passage Till he faced the slave ; Which ne ’ er shook hands , n\n",
      "ll to him , Till he unseamed him from the nave to th ’ chops , And fixed his he\n",
      "cousin , worthy gentleman ! As whence the sun ’ gins his reflection Shipwrackin\n",
      "ping kerns to trust their heels , But the Norweyan lord , surveying vantage , W\n",
      "anquo ? Yes , as sparrows eagles , or the hare the lion . If I say sooth , I mu\n",
      "es , as sparrows eagles , or the hare the lion . If I say sooth , I must report\n",
      "So they doubly redoubled strokes upon the foe . Except they meant to bathe in r\n",
      ", get him surgeons . Who comes here ? The worthy Thane of Ross . What a haste l\n",
      "ms to speak things strange . God save the King . Whence cam ’ st thou , worthy \n",
      "hane ? From Fife , great king , Where the Norweyan banners flout the sky And fa\n",
      "Displaying 25 of 513 matches:\n",
      "y ’ s done , When the battle ’ s lost and won . That will be ere the set of sun\n",
      "Paddock calls . Anon . Fair is foul , and foul is fair ; Hover through the fog \n",
      " foul is fair ; Hover through the fog and filthy air . What bloody man is that \n",
      "his is the sergeant Who , like a good and hardy soldier , fought ’ Gainst my ca\n",
      "spent swimmers that do cling together And choke their art . The merciless Macdo\n",
      "him ) from the Western Isles Of kerns and gallowglasses is supplied ; And Fortu\n",
      "kerns and gallowglasses is supplied ; And Fortune , on his damnèd quarrel smili\n",
      "med him from the nave to th ’ chops , And fixed his head upon our battlements .\n",
      "ns his reflection Shipwracking storms and direful thunders break , So from that\n",
      "rveying vantage , With furbished arms and new supplies of men , Began a fresh a\n",
      "mayed not this our captains , Macbeth and Banquo ? Yes , as sparrows eagles , o\n",
      "re the Norweyan banners flout the sky And fan our people cold . Norway himself \n",
      "nst arm , Curbing his lavish spirit . And to conclude , The victory fell on us \n",
      " . Go , pronounce his present death , And with his former title greet Macbeth .\n",
      "lor ’ s wife had chestnuts in her lap And munched and munched and munched . “ G\n",
      " had chestnuts in her lap And munched and munched and munched . “ Give me , ” q\n",
      "ts in her lap And munched and munched and munched . “ Give me , ” quoth I . “ A\n",
      " But in a sieve I ’ ll thither sail , And , like a rat without a tail , I ’ ll \n",
      "hout a tail , I ’ ll do , I ’ ll do , and I ’ ll do . I ’ ll give thee a wind .\n",
      "ll give thee a wind . Th ’ art kind . And I another . I myself have all the oth\n",
      "other . I myself have all the other , And the very ports they blow ; All the qu\n",
      "imes nine , Shall he dwindle , peak , and pine . Though his bark cannot be lost\n",
      "s , hand in hand , Posters of the sea and land , Thus do go about , about , Thr\n",
      "do go about , about , Thrice to thine and thrice to mine And thrice again , to \n",
      " , Thrice to thine and thrice to mine And thrice again , to make up nine . Peac\n",
      "Displaying 25 of 363 matches:\n",
      "e heath . There to meet with Macbeth . I come , Graymalkin . Paddock calls . An\n",
      "ows eagles , or the hare the lion . If I say sooth , I must report they were As\n",
      "r the hare the lion . If I say sooth , I must report they were As cannons overc\n",
      " wounds Or memorize another Golgotha , I cannot tell — But I am faint . My gash\n",
      "another Golgotha , I cannot tell — But I am faint . My gashes cry for help . So\n",
      " with his former title greet Macbeth . I ’ ll see it done . What he hath lost ,\n",
      "ched and munched . “ Give me , ” quoth I . “ Aroint thee , witch , ” the rump -\n",
      "master o ’ th ’ Tiger ; But in a sieve I ’ ll thither sail , And , like a rat w\n",
      "il , And , like a rat without a tail , I ’ ll do , I ’ ll do , and I ’ ll do . \n",
      "ike a rat without a tail , I ’ ll do , I ’ ll do , and I ’ ll do . I ’ ll give \n",
      "t a tail , I ’ ll do , I ’ ll do , and I ’ ll do . I ’ ll give thee a wind . Th\n",
      " ’ ll do , I ’ ll do , and I ’ ll do . I ’ ll give thee a wind . Th ’ art kind \n",
      "give thee a wind . Th ’ art kind . And I another . I myself have all the other \n",
      "wind . Th ’ art kind . And I another . I myself have all the other , And the ve\n",
      "blow ; All the quarters that they know I ’ th ’ shipman ’ s card . I ’ ll drain\n",
      " they know I ’ th ’ shipman ’ s card . I ’ ll drain him dry as hay . Sleep shal\n",
      " shall be tempest - tossed . Look what I have . Show me , show me . Here I have\n",
      "what I have . Show me , show me . Here I have a pilot ’ s thumb , Wracked as ho\n",
      " ’ s wound up . So foul and fair a day I have not seen . How far is ’ t called \n",
      " fear Things that do sound so fair ? — I ’ th ’ name of truth , Are you fantast\n",
      "rs . Tell me more . By Sinel ’ s death I know I am Thane of Glamis . But how of\n",
      "ll me more . By Sinel ’ s death I know I am Thane of Glamis . But how of Cawdor\n",
      "With such prophetic greeting . Speak , I charge you . The earth hath bubbles , \n",
      " He labored in his country ’ s wrack , I know not ; But treasons capital , conf\n",
      "est consequence . — Cousins , a word , I pray you . Two truths are told As happ\n"
     ]
    }
   ],
   "source": [
    "print(\"These are the concordances for the top three most frequent words in 'Macbeth':\")\n",
    "macbeth.concordance(\"the\")\n",
    "macbeth.concordance(\"and\")\n",
    "macbeth.concordance(\"I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 40636, '.': 33762, 'the': 33275, 'I': 17320, 'and': 16748, 'of': 16498, 'to': 15840, '\"': 15114, 'a': 15076, 'that': 10724, ...})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sherlock = nltk.Text(mycorpus.words('SherlockHolmes.txt'))\n",
    "nltk.FreqDist(sherlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the concordances for the top three most frequent words in 'Sherlock Holmes':\n",
      "Displaying 25 of 36091 matches:\n",
      "PART I ( Being a reprint from the reminiscences of John H . Watson , M \n",
      "of John H . Watson , M . D ., late of the Army Medical Department .) CHAPTER I \n",
      " .) CHAPTER I Mr . Sherlock Holmes In the year 1878 I took my degree of Doctor \n",
      "ok my degree of Doctor of Medicine of the University of London , and proceeded \n",
      "and proceeded to Netley to go through the course prescribed for surgeons in the\n",
      "the course prescribed for surgeons in the army . Having completed my studies th\n",
      "tudies there , I was duly attached to the Fifth Northumberland Fusiliers as Ass\n",
      "land Fusiliers as Assistant Surgeon . The regiment was stationed in India at th\n",
      "he regiment was stationed in India at the time , and before I could join it , t\n",
      "e time , and before I could join it , the second Afghan war had broken out . On\n",
      "ed that my corps had advanced through the passes , and was already deep in the \n",
      " the passes , and was already deep in the enemy ' s country . I followed , howe\n",
      " with many other officers who were in the same situation as myself , and succee\n",
      " at once entered upon my new duties . The campaign brought honours and promotio\n",
      "moved from my brigade and attached to the Berkshires , with whom I served at th\n",
      "he Berkshires , with whom I served at the fatal battle of Maiwand . There I was\n",
      "le of Maiwand . There I was struck on the shoulder by a Jezail bullet , which s\n",
      " by a Jezail bullet , which shattered the bone and grazed the subclavian artery\n",
      ", which shattered the bone and grazed the subclavian artery . I should have fal\n",
      "an artery . I should have fallen into the hands of the murderous Ghazis had it \n",
      " should have fallen into the hands of the murderous Ghazis had it not been for \n",
      " murderous Ghazis had it not been for the devotion and courage shown by Murray \n",
      "nd succeeded in bringing me safely to the British lines . Worn with pain , and \n",
      "ines . Worn with pain , and weak from the prolonged hardships which I had under\n",
      "great train of wounded sufferers , to the base hospital at Peshawar . Here I ra\n",
      "Displaying 25 of 17322 matches:\n",
      "PART I ( Being a reprint from the reminiscenc\n",
      "the Army Medical Department .) CHAPTER I Mr . Sherlock Holmes In the year 1878 \n",
      " Mr . Sherlock Holmes In the year 1878 I took my degree of Doctor of Medicine o\n",
      " . Having completed my studies there , I was duly attached to the Fifth Northum\n",
      "oned in India at the time , and before I could join it , the second Afghan war \n",
      "ad broken out . On landing at Bombay , I learned that my corps had advanced thr\n",
      "lready deep in the enemy ' s country . I followed , however , with many other o\n",
      "in reaching Candahar in safety , where I found my regiment , and at once entere\n",
      " nothing but misfortune and disaster . I was removed from my brigade and attach\n",
      "attached to the Berkshires , with whom I served at the fatal battle of Maiwand \n",
      "at the fatal battle of Maiwand . There I was struck on the shoulder by a Jezail\n",
      "one and grazed the subclavian artery . I should have fallen into the hands of t\n",
      "eak from the prolonged hardships which I had undergone , I was removed , with a\n",
      "nged hardships which I had undergone , I was removed , with a great train of wo\n",
      "o the base hospital at Peshawar . Here I rallied , and had already improved so \n",
      "bask a little upon the verandah , when I was struck down by enteric fever , tha\n",
      "fe was despaired of , and when at last I came to myself and became convalescent\n",
      "me to myself and became convalescent , I was so weak and emaciated that a medic\n",
      "e lost in sending me back to England . I was dispatched , accordingly , in the \n",
      "e months in attempting to improve it . I had neither kith nor kin in England , \n",
      "man to be . Under such circumstances , I naturally gravitated to London , that \n",
      "mpire are irresistibly drained . There I stayed for some time at a private hote\n",
      "existence , and spending such money as I had , considerably more freely than I \n",
      " I had , considerably more freely than I ought . So alarming did the state of m\n",
      "the state of my finances become , that I soon realized that I must either leave\n",
      "Displaying 25 of 17578 matches:\n",
      "edicine of the University of London , and proceeded to Netley to go through the\n",
      " was stationed in India at the time , and before I could join it , the second A\n",
      "rps had advanced through the passes , and was already deep in the enemy ' s cou\n",
      "ere in the same situation as myself , and succeeded in reaching Candahar in saf\n",
      " safety , where I found my regiment , and at once entered upon my new duties . \n",
      "duties . The campaign brought honours and promotion to many , but for me it had\n",
      " for me it had nothing but misfortune and disaster . I was removed from my brig\n",
      "aster . I was removed from my brigade and attached to the Berkshires , with who\n",
      "ail bullet , which shattered the bone and grazed the subclavian artery . I shou\n",
      "azis had it not been for the devotion and courage shown by Murray , my orderly \n",
      " who threw me across a pack - horse , and succeeded in bringing me safely to th\n",
      " the British lines . Worn with pain , and weak from the prolonged hardships whi\n",
      "spital at Peshawar . Here I rallied , and had already improved so far as to be \n",
      " to be able to walk about the wards , and even to bask a little upon the verand\n",
      "For months my life was despaired of , and when at last I came to myself and bec\n",
      "f , and when at last I came to myself and became convalescent , I was so weak a\n",
      "d became convalescent , I was so weak and emaciated that a medical board determ\n",
      "ordingly , in the troopship Orontes , and landed a month later on Portsmouth je\n",
      "had neither kith nor kin in England , and was therefore as free as air -- or as\n",
      "free as an income of eleven shillings and sixpence a day will permit a man to b\n",
      " cesspool into which all the loungers and idlers of the Empire are irresistibly\n",
      "comfortless , meaningless existence , and spending such money as I had , consid\n",
      "at I must either leave the metropolis and rusticate somewhere in the country , \n",
      "aking up my mind to leave the hotel , and to take up my quarters in some less p\n",
      " my quarters in some less pretentious and less expensive domicile . On the very\n"
     ]
    }
   ],
   "source": [
    "print(\"These are the concordances for the top three most frequent words in 'Sherlock Holmes':\")\n",
    "sherlock.concordance(\"the\")\n",
    "sherlock.concordance(\"I\")\n",
    "sherlock.concordance(\"and\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 2950, ',': 1920, \"'\": 1377, '?': 979, 'I': 934, 'you': 835, 'the': 544, 's': 524, 'to': 510, 'it': 434, ...})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breaking = nltk.Text(mycorpus.words('BreakingBadSeason1.txt'))\n",
    "nltk.FreqDist(breaking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the concordances for the top three most frequent words in 'Breaking Bad':\n",
      "Displaying 25 of 935 matches:\n",
      "My name is Walter Hartwell White . I live at 308 Negra Arroyo Lane Albuquer\n",
      " , this is not an admission of guilt . I am speaking to my family now . Skyler \n",
      ". Skyler you are the love of my life . I hope you know that . Walter Junior you\n",
      " learn about me in the next few days . I just want you to know that no matter h\n",
      " know that no matter how it may look , I only had you in my heart . Goodbye . (\n",
      "u think you ' ll be home ? Same time . I don ' t want him dicking you around to\n",
      "again . There was no hot water again . I have an easy fix for that . You wake u\n",
      "to be the first person in the shower . I have an idea . How about buy a new hot\n",
      ". Did you take your Echinacea ? Yeah . I think it ' s getting better . What the\n",
      "n . We ' re watching our cholesterol , I guess . Not me . I want real bacon . N\n",
      "g our cholesterol , I guess . Not me . I want real bacon . Not this fake crap .\n",
      "ur veggie bacon . You all set ? Yeah , I ' m fine . All right , see you at home\n",
      "chemistry is the study of matter . But I prefer to see it as the study of chang\n",
      " Well , that ' s all of life . Right ? I mean , it ' s just It ' s the constant\n",
      "He ' s not coming . He said he quits . I ' m gonna run the register . Bogdan , \n",
      ". Bogdan , no . We talked about this . I ' m shorthanded , Walter . What am I t\n",
      ". I ' m shorthanded , Walter . What am I to do ? Walter ? What am I to do ? Hey\n",
      "r . What am I to do ? Walter ? What am I to do ? Hey , Mr . White ! Make those \n",
      "Dad ! You ' re so very late . Really , I ' m serious , Skyler . I mean , you ' \n",
      "te . Really , I ' m serious , Skyler . I mean , you ' re flat as a washboard . \n",
      "ck 22 . It ' s my daily carry , okay ? I mean , unless you ' re talking , what \n",
      "u can forget the 9 - mil , all right ? I ’ ve seen one of those bounce off a wi\n",
      "t ? Dad , come check this out . Yeah , I see it . Come on , take it . Check it \n",
      "dy listen up , listen up , listen up ! I ' m gonna give a toast . A little toas\n",
      "viduals and placed them into custody . I ' m proud to say the outstanding profe\n",
      "Displaying 25 of 1164 matches:\n",
      "am speaking to my family now . Skyler you are the love of my life . I hope you \n",
      " you are the love of my life . I hope you know that . Walter Junior you ' re my\n",
      " I hope you know that . Walter Junior you ' re my big man . There are going to \n",
      "going to be some things . Things that you ' ll come to learn about me in the ne\n",
      "me in the next few days . I just want you to know that no matter how it may loo\n",
      "o matter how it may look , I only had you in my heart . Goodbye . ( Three weeks\n",
      "elieve it or not . Zero cholesterol . You won ' t even taste the difference . W\n",
      "n taste the difference . What time do you think you ' ll be home ? Same time . \n",
      "e difference . What time do you think you ' ll be home ? Same time . I don ' t \n",
      "ame time . I don ' t want him dicking you around tonight . You get paid till 5 \n",
      "want him dicking you around tonight . You get paid till 5 , you work till 5 , n\n",
      "round tonight . You get paid till 5 , you work till 5 , no later . Hey . Happy \n",
      ". Hey . Happy birthday . Well , thank you . You ' re late again . There was no \n",
      ". Happy birthday . Well , thank you . You ' re late again . There was no hot wa\n",
      "again . I have an easy fix for that . You wake up early , and then you get to b\n",
      "r that . You wake up early , and then you get to be the first person in the sho\n",
      "he millionth and billionth time . Did you take your Echinacea ? Yeah . I think \n",
      " ass ? Good . Eat your veggie bacon . You all set ? Yeah , I ' m fine . All rig\n",
      "? Yeah , I ' m fine . All right , see you at home . Okay , see you . Chemistry \n",
      " right , see you at home . Okay , see you . Chemistry . It is the study of what\n",
      "h your table ? Okay . Ionic bonds Are you done ? Ionic bonds . Chapter 6 . And \n",
      "to your car wash professional . Thank you . Come again . He ' s not coming . He\n",
      "e , huh ? Chad ’ s Girl Oh , my God . You would not believe who ' s cleaning Ch\n",
      "y . Surprise ! Happy Birthday , Dad ! You ' re so very late . Really , I ' m se\n",
      "y , I ' m serious , Skyler . I mean , you ' re flat as a washboard . You look a\n",
      "Displaying 25 of 588 matches:\n",
      "ing to my family now . Skyler you are the love of my life . I hope you know tha\n",
      "at you ' ll come to learn about me in the next few days . I just want you to kn\n",
      " cholesterol . You won ' t even taste the difference . What time do you think y\n",
      "ake up early , and then you get to be the first person in the shower . I have a\n",
      "hen you get to be the first person in the shower . I have an idea . How about b\n",
      "ater heater ? How ' s that idea ? For the millionth and billionth time . Did yo\n",
      " I think it ' s getting better . What the hell is this ? It ' s veggie bacon . \n",
      " . Okay , see you . Chemistry . It is the study of what ? Anyone ? Ben . Chemic\n",
      " is well , technically , chemistry is the study of matter . But I prefer to see\n",
      "of matter . But I prefer to see it as the study of change . Now just just think\n",
      ". Right ? I mean , it ' s just It ' s the constant . It ' s the cycle . It ' s \n",
      "' s just It ' s the constant . It ' s the cycle . It ' s solution , dissolution\n",
      " . He said he quits . I ' m gonna run the register . Bogdan , no . We talked ab\n",
      "lus , P - plus loads , you can forget the 9 - mil , all right ? I ’ ve seen one\n",
      "ce off a windshield one time . Yeah , the way you sh ** t . If you ' re gonna b\n",
      " . Come here . Walt , you got a brain the size of Wisconsin , but we ' re not g\n",
      "ainst you . Because your heart ' s in the right place , man . Your heart ' s in\n",
      "right place , man . Your heart ' s in the right place . We love you , man . We \n",
      "hem into custody . I ' m proud to say the outstanding professionalism of my fel\n",
      "rofessionalism of my fellow agents at the Albuquerque District Office resulted \n",
      "nt of methamphetamine being taken off the streets . Were any shots fired ? No ,\n",
      "ired ? No , ma ' am . Our agents took the suspects by surprise . Damn , the TV \n",
      "ook the suspects by surprise . Damn , the TV does add ten pounds . Ten pounds ?\n",
      "uh ? As I say , it ' s a good day for the citizens of Albuquerque when we can p\n",
      "ue when we can put this big a dent in the local drug trade . Wow . But that ' s\n"
     ]
    }
   ],
   "source": [
    "print(\"These are the concordances for the top three most frequent words in 'Breaking Bad':\")\n",
    "breaking.concordance(\"I\")\n",
    "breaking.concordance(\"you\")\n",
    "breaking.concordance(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
