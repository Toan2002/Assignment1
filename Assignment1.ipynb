{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 1 - Group 7*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpra \n",
    "This assignment uses texts from 3 different genres: ...\n",
    "\n",
    "Sources:\n",
    "https://sherlock-holm.es/stories/plain-text/cano.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import matplotlib\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect of corpus in Corpora into a list\n",
    "corpusList = os.listdir(os.getcwd() + \"/Corpora/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open .txt file, clean all punctuations and split\n",
    "def readCleanSplit(corpus):\n",
    "    with open(\"./Corpora/\" + corpus, 'r') as f:\n",
    "        text = f.read()\n",
    "        cleanedText = re.sub(\" *[^\\w\\s]+\", \" \", text)\n",
    "        splitedText = cleanedText.split()\n",
    "    return splitedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of macbethspoken.txt is 16708\n",
      "The length of BreakingBadSeason1.txt is 24875\n",
      "The length of SherlockHolmes.txt is 668869\n"
     ]
    }
   ],
   "source": [
    "# remove all punctuations and get length\n",
    "def getLength(corpus):\n",
    "    length = len(readCleanSplit(corpus))\n",
    "    return length\n",
    "\n",
    "# print result\n",
    "for corpus in corpusList:\n",
    "    print(\"The length of {} is {}\".format(corpus, getLength(corpus)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lexical diversity of macbethspoken.txt is 0.18996888\n",
      "The lexical diversity of BreakingBadSeason1.txt is 0.11798995\n",
      "The lexical diversity of SherlockHolmes.txt is 0.02869172\n"
     ]
    }
   ],
   "source": [
    "# define lexical diversity function\n",
    "def lexDiv(corpus):\n",
    "    wordList = readCleanSplit(corpus)\n",
    "    tokens = len(wordList)\n",
    "    types = len(set(w.lower() for w in wordList))\n",
    "    return types / tokens\n",
    "\n",
    "# print result\n",
    "for corpus in corpusList:\n",
    "    print(\"The lexical diversity of {} is {:.8f}\".format(corpus,lexDiv(corpus)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "macbethspoken.txt:\n",
      "The 10 most common words starting with 'a': \n",
      "[('and', 513), ('a', 215), ('all', 91), ('as', 88), ('are', 74), ('at', 52), ('am', 30), ('an', 27), ('again', 21), ('art', 19)]\n",
      "The 10 most common words starting with 'e': \n",
      "[('each', 13), ('every', 13), ('ere', 12), ('even', 12), ('eyes', 11), ('else', 11), ('eye', 11), ('er', 10), ('enough', 10), ('ever', 8)]\n",
      "The 10 most common words starting with 'i': \n",
      "[('i', 363), ('in', 195), ('is', 187), ('it', 151), ('if', 45), ('into', 11), ('itself', 9), ('issue', 6), ('indeed', 5), ('innocent', 5)]\n",
      "The 10 most common words starting with 'o': \n",
      "[('of', 325), ('our', 119), ('on', 62), ('o', 48), ('or', 36), ('one', 30), ('out', 26), ('own', 17), ('other', 15), ('only', 12)]\n",
      "The 10 most common words starting with 'u': \n",
      "[('upon', 63), ('us', 55), ('up', 26), ('under', 8), ('use', 6), ('unto', 3), ('undone', 3), ('unnatural', 3), ('unfix', 2), ('used', 2)]\n",
      "\n",
      "BreakingBadSeason1.txt:\n",
      "The 10 most common words starting with 'a': \n",
      "[('a', 432), ('and', 290), ('all', 151), ('about', 124), ('are', 118), ('at', 100), ('as', 50), ('an', 41), ('any', 30), ('am', 29)]\n",
      "The 10 most common words starting with 'e': \n",
      "[('even', 32), ('enough', 19), ('ever', 18), ('every', 18), ('emilio', 15), ('elliott', 15), ('else', 11), ('excuse', 11), ('easy', 10), ('everybody', 9)]\n",
      "The 10 most common words starting with 'i': \n",
      "[('i', 935), ('it', 570), ('is', 264), ('in', 220), ('if', 62), ('into', 15), ('isn', 13), ('idea', 12), ('iron', 5), ('interest', 5)]\n",
      "The 10 most common words starting with 'o': \n",
      "[('of', 236), ('on', 151), ('out', 110), ('okay', 104), ('one', 81), ('oh', 75), ('or', 51), ('our', 48), ('off', 37), ('over', 26)]\n",
      "The 10 most common words starting with 'u': \n",
      "[('up', 119), ('us', 50), ('used', 18), ('uh', 16), ('understand', 15), ('until', 11), ('use', 7), ('um', 6), ('uncle', 4), ('understanding', 4)]\n",
      "\n",
      "SherlockHolmes.txt:\n",
      "The 10 most common words starting with 'a': \n",
      "[('and', 17578), ('a', 15840), ('as', 4755), ('at', 4625), ('all', 2418), ('an', 2297), ('are', 2129), ('about', 1075), ('am', 1009), ('any', 938)]\n",
      "The 10 most common words starting with 'e': \n",
      "[('eyes', 642), ('every', 489), ('ever', 433), ('enough', 399), ('end', 398), ('even', 369), ('evening', 306), ('each', 259), ('else', 195), ('entered', 186)]\n",
      "The 10 most common words starting with 'i': \n",
      "[('i', 17325), ('it', 11095), ('in', 10756), ('is', 6648), ('if', 2065), ('into', 1462), ('its', 458), ('instant', 293), ('indeed', 265), ('inspector', 262)]\n",
      "The 10 most common words starting with 'o': \n",
      "[('of', 16773), ('on', 2759), ('one', 2590), ('out', 1863), ('our', 1709), ('or', 1350), ('only', 1086), ('over', 1078), ('other', 881), ('own', 736)]\n",
      "The 10 most common words starting with 'u': \n",
      "[('upon', 2586), ('up', 1662), ('us', 1528), ('until', 460), ('under', 331), ('understand', 252), ('use', 180), ('used', 164), ('usual', 78), ('unless', 75)]\n"
     ]
    }
   ],
   "source": [
    "# top 10 words with given initial\n",
    "def initial_top10(corpus, initial):\n",
    "    wordList = readCleanSplit(corpus)\n",
    "    # only put words with initial X in list\n",
    "    processedList = []\n",
    "    for w in wordList:\n",
    "        if w[0] == initial.upper() or w[0] == initial.lower():\n",
    "            processedList.append(w.lower())\n",
    "            \n",
    "    fDist = nltk.FreqDist(nltk.Text(processedList))\n",
    "    return fDist.most_common(10)\n",
    "    \n",
    "for corpus in corpusList:\n",
    "    print(\"\\n{}:\".format(corpus))\n",
    "    for vowel in \"aeiou\":\n",
    "        print(\"The 10 most common words starting with '{}': \\n{}\".format(vowel, initial_top10(corpus,vowel)))\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
